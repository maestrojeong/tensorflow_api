{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.Session()\n",
    "def print_variables(keys):\n",
    "    i = 0\n",
    "    print(keys)\n",
    "    while True:\n",
    "        try:\n",
    "            print(tf.get_collection(keys)[i])\n",
    "            i+=1\n",
    "        except IndexError:\n",
    "            break;\n",
    "def print_tensor(x):\n",
    "    print(sess.run(x))\n",
    "def get_shape(tensor):\n",
    "    return tensor.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Multiple gradients and constant case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([108], dtype=int32)]\n",
      "[array([54], dtype=int32)]\n",
      "[array([108], dtype=int32)]\n",
      "[array([72], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.constant([2]) # 1*2\n",
    "w2 = tf.constant([3]) # 1*2\n",
    "\n",
    "z1 = w1*w1*w2*w2*w2 # w1^2 w2^3 \n",
    "z1_w1 = tf.gradients(z1, w1)  # 2w1*w2^3\n",
    "z1_w1_w1 = tf.gradients(z1_w1, w1)# 2*w2^3\n",
    "z1_w1_w2 = tf.gradients(z1_w1, w2)# 2w1*3*w2^2\n",
    "z1_w1_w2_w2 = tf.gradients(z1_w1_w2, w2)# 2w1*6*w2\n",
    "print_tensor(z1_w1)\n",
    "print_tensor(z1_w1_w1)\n",
    "print_tensor(z1_w1_w2)\n",
    "print_tensor(z1_w1_w2_w2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. variable case and other args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4], dtype=int32), array([2], dtype=int32)]\n",
      "[array([20], dtype=int32), array([10], dtype=int32)]\n",
      "[array([-3], dtype=int32), array([-1], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable([2]) # 1*2\n",
    "w2 = tf.Variable([3]) # 1*2\n",
    "\n",
    "z1 = w1*w1 + 2*w2 # w1^2 + 2 w2 \n",
    "z2 = w1 + w2 # w1+w2\n",
    "\n",
    "grads = tf.gradients(ys = z1, xs = [w1, w2]) # => 2w1, 2\n",
    "grads2 = tf.gradients(ys = z1, grad_ys = [5], xs = [w1, w2]) # => 5*(2w1, 2)\n",
    "grads3 = tf.gradients(ys = [z1, z2], grad_ys=[-1, 1], xs = [w1, w2]) # -1*(2w1,-2) + 1*(1, 1) \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(grads)\n",
    "print_tensor(grads2)\n",
    "print_tensor(grads3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.stop_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "c_stoped = tf.stop_gradient(c)\n",
    "\n",
    "d = 2*a + 3*b\n",
    "\n",
    "e = tf.add(c_stoped, d)\n",
    "\n",
    "gradients = tf.gradients(e, xs=[a, b])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print_tensor(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, <tf.Tensor 'gradients_4/add_5_grad/Reshape_1:0' shape=() dtype=float32>]\n",
      "1.0\n",
      "[2.0, 1.9]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(2.0)\n",
    "w2 = tf.Variable(2.0)\n",
    "a = w1*3.0 + w2*2.0\n",
    "a_stopped = tf.stop_gradient(a)\n",
    "\n",
    "# a_stopped = w1*3.0\n",
    "# b= a*w2\n",
    "b = a_stopped + w2\n",
    "\n",
    "gradients = tf.gradients(xs = tf.trainable_variables()[-2:], ys = b)\n",
    "\n",
    "train_op = tf.train.RMSPropOptimizer(0.1).apply_gradients(zip(gradients, tf.trainable_variables()[-2:]))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_op)\n",
    "print(gradients)\n",
    "print_tensor(gradients[1])\n",
    "print_tensor([w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.get_variable() v.s tf.variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Failed example of sharing variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=int32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(1,) dtype=int32_ref>\n",
      "<tf.Variable 'Variable_2:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Variable_4:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'Variable_5:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'v:0' shape=(2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'v_1:0' shape=(2, 3) dtype=float32_ref>\n",
      "<tf.Variable 'v_2:0' shape=(2, 3) dtype=float32_ref>\n",
      "[[-0.59384066 -0.70466059 -0.77709585]\n",
      " [ 1.00320792 -1.24869776 -0.89308441]]\n",
      "[[-0.02978455 -1.27130759  0.30037636]\n",
      " [ 2.0305264   0.35971001  1.84034228]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Bad example of defining the name of variables\n",
    "v = tf.Variable(tf.random_normal([2,3]), name='v')\n",
    "v2 = tf.Variable(tf.random_normal([2,3]), name='v')\n",
    "x = tf.get_variable('v', [2, 3], initializer= tf.constant_initializer(0.0))\n",
    "\n",
    "print_variables('trainable_variables')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(v)\n",
    "print_tensor(v2)\n",
    "print_tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. tf.get_varaible => to share variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42261541  0.16263834  1.64886343]\n",
      " [ 1.19830573 -0.6385743  -0.69327295]]\n",
      "[[ 0.42261541  0.16263834  1.64886343]\n",
      " [ 1.19830573 -0.6385743  -0.69327295]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('hi') as scope:\n",
    "    v = tf.get_variable('a', [2,3],initializer= tf.random_normal_initializer())\n",
    "    scope.reuse_variables()\n",
    "    x = tf.get_variable('a')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print_tensor(v)\n",
    "    print_tensor(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.control_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.]\n",
      "[ 2.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.])\n",
    "x_op = tf.assign(x, [2.])\n",
    "with tf.control_dependencies([x_op]):\n",
    "    y = tf.add(x, [1.])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(y)\n",
    "print_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.]\n",
      "[ 1.]\n",
      "[ 2.]\n",
      "[ 2.]\n",
      "[ 3.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.])\n",
    "x_op = tf.assign(x, [2.])\n",
    "y = tf.add(x, [1.])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(y)\n",
    "print_tensor(x)\n",
    "print_tensor(x_op)\n",
    "print_tensor(x)\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train.exponential_decay() and global_step\n",
    "**decayed_learning_rate** = learning_rate $\\times$ decay_rate ^ (global_step / decay_steps)    \n",
    "\n",
    "* **learning_rate**:  The initial learning rate.  \n",
    "* **global_step**: Global step to use for the decay computation. Must not be negative.  \n",
    "* **decay_steps**:  Must be positive. See the decay computation above. \n",
    "* **decay_rate**: A scalar float32 or float64 Tensor or a Python number. The decay rate.\n",
    "* **staircase**: Boolean. It True decay the learning rate at discrete intervals\n",
    "* **name**: String. Optional name of the operation. Defaults to 'ExponentialDecay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only train_variable : <tf.Variable 'w:0' shape=(1,) dtype=float32_ref>\n",
      "[ 0.26595926]\n",
      "[-0.73967505]\n",
      "i | global_step | learning_rate\n",
      "0 |          1|0.10000000149011612|\n",
      "i | global_step | learning_rate\n",
      "1 |          2|0.09600000083446503|\n",
      "i | global_step | learning_rate\n",
      "2 |          3|0.09600000083446503|\n",
      "i | global_step | learning_rate\n",
      "3 |          4|0.09216000139713287|\n",
      "i | global_step | learning_rate\n",
      "4 |          5|0.09216000139713287|\n",
      "i | global_step | learning_rate\n",
      "5 |          6|0.0884735956788063|\n",
      "i | global_step | learning_rate\n",
      "6 |          7|0.0884735956788063|\n",
      "i | global_step | learning_rate\n",
      "7 |          8|0.08493465185165405|\n",
      "i | global_step | learning_rate\n",
      "8 |          9|0.08493465185165405|\n",
      "i | global_step | learning_rate\n",
      "9 |          10|0.08153726160526276|\n",
      "[ 1.31700361]\n",
      "[-0.73967505]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1., 2., 3.]\n",
    "y_data = [1., 2., 3.]\n",
    "\n",
    "w = tf.Variable(tf.random_uniform([1], -1.0, 1.0),name ='w')\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0),name ='b')\n",
    "\n",
    "hypothesis = w * x_data + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate= 0.1, global_step= global_step,\n",
    "                                        decay_steps = 2, decay_rate = 0.96, staircase=True)\n",
    "\n",
    "#train only w not b\n",
    "var_list = []\n",
    "var_list.append(tf.get_collection(\"trainable_variables\")[0])\n",
    "print(\"Only train_variable : {}\".format(var_list[0]))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss = cost\n",
    "                                                                  ,global_step=global_step\n",
    "                                                                 ,var_list = var_list\n",
    "                                                                  #,var_list = tf.get_collection(\"trainable_variables\")\n",
    "                                                                 )\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print_tensor(w)\n",
    "print_tensor(b)\n",
    "for step in range(10):\n",
    "    sess.run(train)\n",
    "    print(\"i | global_step | learning_rate\")\n",
    "    print(\"{} |          {}|{}|\".format(step, sess.run(global_step), sess.run(learning_rate)))\n",
    "print_tensor(w)\n",
    "print_tensor(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train.ExponentialMovingAverage\n",
    "* **semi_weight_track** explaines how shadow variable in ema works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_variables\n",
      "<tf.Variable 'w:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'b:0' shape=() dtype=float32_ref>\n",
      "moving_average_variables\n",
      "ema.average(w) : variable\n",
      "<tf.Variable 'w/ExponentialMovingAverage:0' shape=() dtype=float32_ref>\n",
      "ema.average_name(w) : name\n",
      "w/ExponentialMovingAverage\n",
      "<class 'dict'>\n",
      "ema.variables_to_restore() : name to variable\n",
      "{'w/ExponentialMovingAverage': <tf.Variable 'w:0' shape=() dtype=float32_ref>, 'b/ExponentialMovingAverage': <tf.Variable 'b:0' shape=() dtype=float32_ref>}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUEopZacJQSmlFAD/D2OGRQozeZzyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaf96de390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = [1., 2., 3.]\n",
    "y_data = [1., 2., 3.]\n",
    "\n",
    "w = tf.Variable(1.0, name ='w')\n",
    "b = tf.Variable(0.1, name ='b')\n",
    "\n",
    "hypothesis = w * x_data + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "print_variables(\"trainable_variables\")\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss = cost, var_list = [w, b])\n",
    "\n",
    "decay_rate = 0.3\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(decay = 0.3)\n",
    "\n",
    "print_variables(\"moving_average_variables\")\n",
    "\n",
    "with tf.control_dependencies([train]):#after train ema apply\n",
    "     train_wrapped = ema.apply([w, b])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "print(\"ema.average(w) : variable\")\n",
    "print(ema.average(w))\n",
    "print(\"ema.average_name(w) : name\")\n",
    "print(ema.average_name(w))\n",
    "print(type(ema.variables_to_restore()))\n",
    "print(\"ema.variables_to_restore() : name to variable\")\n",
    "print(ema.variables_to_restore())\n",
    "\n",
    "weight_track = []\n",
    "ema_weight_track = []\n",
    "x_axis = []\n",
    "semi_weight_track = []\n",
    "for step in range(10):\n",
    "    weight_track.append(sess.run(w))\n",
    "    ema_weight_track.append(sess.run(ema.average(w)))# already initialized with weight\n",
    "    \n",
    "    if step==0:\n",
    "        semi_weight_track.append(sess.run(w))\n",
    "    else:\n",
    "        semi_weight_track.append(weight_track[-1]*(1-decay_rate) + semi_weight_track[-1]*decay_rate)    \n",
    "    \n",
    "    x_axis.append(step)\n",
    "    sess.run(train_wrapped)\n",
    "\n",
    "plt.plot(x_axis, weight_track, 'ro',label = 'weight')\n",
    "plt.plot(x_axis, ema_weight_track, 'bo', label = 'ema_weight')\n",
    "plt.plot(x_axis, semi_weight_track, 'g', label = 'semi_weight')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[1 2]\n",
      "y = tf.add(x, 1)\n",
      "[2 3]\n",
      "x+1\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2])\n",
    "y = tf.add(x, 1)\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"y = tf.add(x, 1)\")\n",
    "print_tensor(y)\n",
    "print(\"x+1\")\n",
    "print_tensor(x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.add_ n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[ 1.  2.  3.]\n",
      "y\n",
      "[ 4.  5.  6.]\n",
      "z\n",
      "[ 7.  8.  9.]\n",
      "w = tf.add_n([x,y,z])\n",
      "[ 12.  15.  18.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3],dtype = tf.float32)\n",
    "y = tf.constant([4, 5, 6],dtype = tf.float32)\n",
    "z = tf.constant([7, 8, 9],dtype = tf.float32)\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"y\")\n",
    "print_tensor(y)\n",
    "print(\"z\")\n",
    "print_tensor(z)\n",
    "w = tf.add_n([x, y, z])\n",
    "print(\"w = tf.add_n([x,y,z])\")\n",
    "print_tensor(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.scatter_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[ 1.  1.  1.]\n",
      " [ 2.  2.  2.]\n",
      " [ 3.  3.  3.]\n",
      " [ 4.  4.  4.]]\n",
      "y\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "z = tf.scatter_add(ref = y, indices=0, updates = x)\n",
      "[[ 2.  2.  2.]\n",
      " [ 7.  7.  7.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,1,1], [2,2,2], [3,3,3], [4,4,4]], dtype =tf.float32)\n",
    "y = tf.Variable(tf.zeros(shape=[6, 3], dtype=tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"y\")\n",
    "print_tensor(y)\n",
    "z = tf.scatter_add(ref = y, indices=[4, 0, 1, 1], updates = x)\n",
    "print(\"z = tf.scatter_add(ref = y, indices=0, updates = x)\")\n",
    "print_tensor(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.matmul v.s. tf.multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **tf.matmul** argument should be (rank2 tensor, rank2 tensor)\n",
    "* **tf.multipy** only applies to \n",
    "1. (same rank tensor, same rank tensor)  \n",
    "2. ($1\\times 1$ tensor, some tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "y\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "z1 = tf.multiply(x, y)\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "z2 = tf.matmul(x, y)\n",
      "[[2 2]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,1],[1,1]])\n",
    "y = tf.constant([[1,1],[1,1]])\n",
    "z1 = tf.multiply(x, y)\n",
    "z2 = tf.matmul(x, y)\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"y\")\n",
    "print_tensor(y)\n",
    "print(\"z1 = tf.multiply(x, y)\")\n",
    "print_tensor(z1)\n",
    "print(\"z2 = tf.matmul(x, y)\")\n",
    "print_tensor(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2,)\n",
      "[1 3]\n",
      "y : (2,)\n",
      "[2 6]\n",
      "w : (2, 2)\n",
      "[[1 2]\n",
      " [2 1]]\n",
      "x*y\n",
      "[ 2 18]\n",
      "z = tf.multiply(x, y)\n",
      "[ 2 18]\n",
      "tf.multiply([3], x)\n",
      "[3 9]\n",
      "tf.multiply(w, x)\n",
      "[[1 6]\n",
      " [2 3]]\n",
      "x_r1 = tf.reshape(x, [1,2])\n",
      "[[1 3]]\n",
      "x_r2 = tf.reshape(x, [2,1])\n",
      "[[1]\n",
      " [3]]\n",
      "w*x_r1\n",
      "[[1 6]\n",
      " [2 3]]\n",
      "w*x_r2\n",
      "[[1 2]\n",
      " [6 3]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,3])\n",
    "y = tf.constant([2,6])\n",
    "z = tf.multiply(x, y)\n",
    "w = tf.constant([[1,2],[2,1]])\n",
    "print(\"x : {}\".format(x.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"y : {}\".format(y.get_shape()))\n",
    "print_tensor(y)\n",
    "print(\"w : {}\".format(w.get_shape()))\n",
    "print_tensor(w)\n",
    "print(\"x*y\")\n",
    "print_tensor(x*y)\n",
    "print(\"z = tf.multiply(x, y)\")\n",
    "print_tensor(z)\n",
    "print(\"tf.multiply([3], x)\")\n",
    "print_tensor(tf.multiply([3], x))\n",
    "print(\"tf.multiply(w, x)\")\n",
    "print_tensor(tf.multiply(w,x))\n",
    "x_r1 = tf.reshape(x, [1,2])\n",
    "x_r2 = tf.reshape(x, [2,1])\n",
    "print(\"x_r1 = tf.reshape(x, [1,2])\")\n",
    "print_tensor(x_r1)\n",
    "print(\"x_r2 = tf.reshape(x, [2,1])\")\n",
    "print_tensor(x_r2)\n",
    "print(\"w*x_r1\")\n",
    "print_tensor(w*x_r1)\n",
    "print(\"w*x_r2\")\n",
    "print_tensor(w*x_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[ 1.  2.  3.]\n",
      "y\n",
      "[ 2.  4.  6.]\n",
      "x/y\n",
      "[ 0.5  0.5  0.5]\n",
      "z = tf.div(x, y)\n",
      "[ 0.5  0.5  0.5]\n",
      "tf.div(1., 2.)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3], dtype = tf.float32)\n",
    "y = tf.constant([2,4,6], dtype = tf.float32)\n",
    "z = tf.div(x, y)\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"y\")\n",
    "print_tensor(y)\n",
    "print(\"x/y\")\n",
    "print_tensor(x/y)\n",
    "print(\"z = tf.div(x, y)\")\n",
    "print_tensor(z)\n",
    "print(\"tf.div(1., 2.)\")\n",
    "print_tensor(tf.div(1., 2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.exp\n",
    "안에는 무조건 실수 여야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.71828\n"
     ]
    }
   ],
   "source": [
    "print_tensor(tf.exp(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[ 1.  2.  3.]\n",
      "tf.sqrt(x)\n",
      "[ 1.          1.41421354  1.73205078]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3], dtype = tf.float32)\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print('tf.sqrt(x)')\n",
    "print_tensor(tf.sqrt(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the location is represented by indices, then the lotcation takes **on_value**, and the other takes **off_value**\n",
    "* input array rank : $N$ $\\Rightarrow$ output array rank : $N+1$\n",
    "* **Total depth** determines the number of last rank component\n",
    "> input_shape : $[r_0, r_1, r_2, \\cdots r_N]$ changes to \n",
    "> ouput_shape : $[r_0, r_1, r_2, \\cdots r_N, depth]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 2)\n",
      "[[1 3]\n",
      " [3 2]]\n",
      "x_one_hot : (2, 2, 6)\n",
      "[[[-1.  2. -1. -1. -1. -1.]\n",
      "  [-1. -1. -1.  2. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.  2. -1. -1.]\n",
      "  [-1. -1.  2. -1. -1. -1.]]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,3],[3,2]])\n",
    "x_one_hot = tf.one_hot(indices = x, depth=6, on_value=2.0, off_value=-1.0, dtype='float32')\n",
    "print(\"x : {}\".format(x.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"x_one_hot : {}\".format(x_one_hot.get_shape()))\n",
    "print_tensor(x_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.dropout(x, keep_prob, noise_shape)\n",
    "* **x** : input\n",
    "* **keep_prob** : (0,1]\n",
    "* **noise_shape** : \n",
    "> default to be shape(x)  \n",
    "> if $noise shape[i] == get shape(x)[i]$\n",
    "=> independent decision  \n",
    "> ex) $shape(x) = [k, l, m, n], [k, 1, 1, n]$\n",
    "dim 1, 2 is determined togther\n",
    "dim 0, 3 is determined independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[ 1.  2.  4.  6.]\n",
      "tf.nn.dropout(x, keep_prob = 0.25)\n",
      "[  4.   0.   0.  24.]\n",
      "[  0.   8.   0.  24.]\n",
      "[ 0.  8.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 4., 6.])\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"tf.nn.dropout(x, keep_prob = 0.25)\")\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.25))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.25))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 2, 3)\n",
      "[[[  1.   2.   3.]\n",
      "  [  4.   5.   6.]]\n",
      "\n",
      " [[  7.   8.   9.]\n",
      "  [ 10.  11.  12.]]]\n",
      "tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3])\n",
      "[[[  0.   0.   0.]\n",
      "  [  0.  10.  12.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.  22.  24.]]]\n",
      "[[[  2.   4.   6.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 14.  16.  18.]\n",
      "  [  0.   0.   0.]]]\n",
      "[[[  0.   0.   0.]\n",
      "  [  8.  10.   0.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [ 20.  22.   0.]]]\n",
      "[[[  2.   4.   0.]\n",
      "  [  8.  10.  12.]]\n",
      "\n",
      " [[ 14.  16.   0.]\n",
      "  [ 20.  22.  24.]]]\n",
      "tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 1, 3])\n",
      "[[[  2.   0.   0.]\n",
      "  [  8.   0.   0.]]\n",
      "\n",
      " [[ 14.   0.  18.]\n",
      "  [ 20.   0.  24.]]]\n",
      "[[[  2.   4.   0.]\n",
      "  [  8.  10.   0.]]\n",
      "\n",
      " [[ 14.   0.  18.]\n",
      "  [ 20.   0.  24.]]]\n",
      "[[[  0.   0.   6.]\n",
      "  [  0.   0.  12.]]\n",
      "\n",
      " [[ 14.  16.  18.]\n",
      "  [ 20.  22.  24.]]]\n",
      "[[[  2.   4.   0.]\n",
      "  [  8.  10.   0.]]\n",
      "\n",
      " [[  0.   0.  18.]\n",
      "  [  0.  22.   0.]]]\n",
      "tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1])\n",
      "[[[  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [ 20.  22.  24.]]]\n",
      "[[[  2.   4.   6.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[ 14.  16.  18.]\n",
      "  [  0.   0.   0.]]]\n",
      "[[[ 2.  4.  6.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n",
      "[[[  0.   0.   0.]\n",
      "  [  8.  10.  12.]]\n",
      "\n",
      " [[ 14.  16.  18.]\n",
      "  [ 20.  22.  24.]]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[1.,2.,3.],[4.,5.,6.]],[[7.,8.,9.],[10.,11.,12.]]])\n",
    "print(\"x : {}\".format(x.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3])\")\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[1, 2, 3]))\n",
    "print(\"tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 1, 3])\")\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 1, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 1, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 1, 3]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 3]))\n",
    "print(\"tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1])\")\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1]))\n",
    "print_tensor(tf.nn.dropout(x, keep_prob=0.5, noise_shape=[2, 2, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.xw_plus_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2]])\n",
    "w = tf.constant([[3],[1]])\n",
    "b = tf.constant([1])\n",
    "# 1*3 + 2*1+1= 6\n",
    "print_tensor(tf.nn.xw_plus_b(x,w,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.embedding_lookup(params, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change ids to params embedding[m, n]  \n",
    "type of elements in ids should be int(less than m)  \n",
    "ids are any size of tensor.  \n",
    "Every elements of ids changes to corresponding params[i]\n",
    "* See also with **tf.gather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding : (3, 4)\n",
      "[[ 0.57905591  0.63686681  0.31841695  0.27772033]\n",
      " [ 0.02685702  0.94557905  0.69220269  0.49113345]\n",
      " [ 0.832546    0.88265514  0.96874344  0.10698855]]\n",
      "x = tf.nn.embedding_lookup(embedding, [2, 1, 2, 0])\n",
      "[[ 0.832546    0.88265514  0.96874344  0.10698855]\n",
      " [ 0.02685702  0.94557905  0.69220269  0.49113345]\n",
      " [ 0.832546    0.88265514  0.96874344  0.10698855]\n",
      " [ 0.57905591  0.63686681  0.31841695  0.27772033]]\n",
      "tf.reduce_mean(x)\n",
      "[ 0.56775123  0.83693904  0.73702669  0.24570772]\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.Variable(tf.random_uniform([3, 4]))\n",
    "x = tf.nn.embedding_lookup(embedding, [2, 1, 2, 0])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"embedding : {}\".format(embedding.get_shape()))\n",
    "print_tensor(embedding)\n",
    "print(\"x = tf.nn.embedding_lookup(embedding, [2, 1, 2, 0])\")\n",
    "print_tensor(x)\n",
    "print(\"tf.reduce_mean(x)\")\n",
    "print_tensor(tf.reduce_mean(x, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[5 6]\n",
      " [7 8]]\n",
      "[[1 2]\n",
      " [5 6]\n",
      " [3 4]\n",
      " [7 8]\n",
      " [5 6]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "embedding1 = tf.Variable([[1,2],[3,4]])\n",
    "embedding2 = tf.Variable([[5,6],[7,8]])\n",
    "x = tf.nn.embedding_lookup([embedding1, embedding2], [0,1,2,3,1,2], partition_strategy='mod')\n",
    "y = tf.nn.embedding_lookup([embedding1, embedding2], [0,1,2,3,1,2], partition_strategy='div')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(embedding1)\n",
    "print_tensor(embedding2)\n",
    "print_tensor(x)\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(1)\n",
    "y = tf.Variable(2)\n",
    "x_op = tf.assign(x, x+1)\n",
    "y_op = tf.assign(y, y*2)\n",
    "\n",
    "ops = tf.group(x_op, y_op)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(ops)\n",
    "\n",
    "print_tensor(x)\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[1, 1, 1], [1, 1, 1]]\n",
      "tf.reduce_sum(x)\n",
      "6\n",
      "tf.reduce_sum(x, 0)\n",
      "[2 2 2]\n",
      "tf.reduce_sum(x, 1)\n",
      "[3 3]\n",
      "tf.reduce_sum(x, [0,1])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x= [[1, 1, 1], [1, 1, 1]]\n",
    "print(\"x\")\n",
    "print(x)\n",
    "print(\"tf.reduce_sum(x)\")\n",
    "print_tensor(tf.reduce_sum(x))\n",
    "print(\"tf.reduce_sum(x, 0)\")\n",
    "print_tensor(tf.reduce_sum(x, 0))\n",
    "print(\"tf.reduce_sum(x, 1)\")\n",
    "print_tensor(tf.reduce_sum(x, 1))\n",
    "print(\"tf.reduce_sum(x, [0,1])\")\n",
    "print_tensor(tf.reduce_sum(x, [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [-1. -1.  1.]]\n",
      "[ 3.7416575   1.73205078]\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[1,2,3],[-1,-1,1]], dtype = tf.float32)\n",
    "norm_c = tf.norm(c, axis=1)\n",
    "print_tensor(c) # sqrt(1*1+2*2+3*3)\n",
    "print_tensor(norm_c) #sqrt(1+1+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "<dtype: 'float32'>\n",
      "y = tf.cast(x,tf.int32)\n",
      "[1]\n",
      "<dtype: 'int32'>\n",
      "x is unchanged\n",
      "<dtype: 'float32'>\n",
      "z = tf.cast(x, tf.bool)\n",
      "<dtype: 'bool'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1.8])\n",
    "print(\"x\")\n",
    "print(x.dtype)\n",
    "y = tf.cast(x, tf.int32)\n",
    "print(\"y = tf.cast(x,tf.int32)\")\n",
    "print_tensor(y)\n",
    "print(y.dtype)\n",
    "print(\"x is unchanged\")\n",
    "print(x.dtype)\n",
    "z = tf.cast(x,'bool')\n",
    "print(\"z = tf.cast(x, tf.bool)\")\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : <class 'list'>\n",
      "[[0.5, 1.5, 0.1], [2.2, 1.3, 1.7]]\n",
      "y : <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Tensor(\"Const_18:0\", shape=(2, 3), dtype=float32)\n",
      "[[ 0.5         1.5         0.1       ]\n",
      " [ 2.20000005  1.29999995  1.70000005]]\n"
     ]
    }
   ],
   "source": [
    "x = [[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]]\n",
    "print(\"x : {}\".format(type(x)))\n",
    "print(x)\n",
    "y = tf.convert_to_tensor(x)\n",
    "print(\"y : {}\".format(type(y)))\n",
    "print(y)\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [[1 2 3]\n",
      " [2 3 1]]\n",
      "tf.argmax(x,0)\n",
      "[1 1 0]\n",
      "tf.argmax(x,1)\n",
      "[2 1]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[2,3,1]])\n",
    "print(\"x : {}\".format(sess.run(x)))\n",
    "print(\"tf.argmax(x,0)\")\n",
    "print_tensor(tf.argmax(x,0))\n",
    "print(\"tf.argmax(x,1)\")\n",
    "print_tensor(tf.argmax(x,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print_tensor(tf.ones(shape=[3, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.random_uniform\n",
    "    default : random_uniform[0 to 1] with the shape\n",
    "    min_val, max_val to control random_unirom[min_val to 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tf.random_uniform([2,3])\n",
      "[[ 0.24782479  0.75386453  0.28676355]\n",
      " [ 0.95951402  0.83935571  0.51980698]]\n",
      "y : tf.random_uniform([2,3],minval=2, maxval=3)\n",
      "[[ 2.04688263  2.96229172  2.25560236]\n",
      " [ 2.29559135  2.70268464  2.4248538 ]]\n",
      "tf.get_collection(\"variables\")[-1]\n",
      "<tf.Variable 'Variable_6:0' shape=(2, 3) dtype=float32_ref>\n",
      "z : tf.Variable(y)\n",
      "[[ 2.73688126  2.54293752  2.4212153 ]\n",
      " [ 2.2127378   2.96805811  2.76424026]]\n",
      "<tf.Variable 'Variable_7:0' shape=(2,) dtype=int32_ref>\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_uniform([2,3])# almost like a constant\n",
    "print(\"x : tf.random_uniform([2,3])\")\n",
    "print_tensor(x)\n",
    "y = tf.random_uniform([2,3],minval=2, maxval=3)\n",
    "print(\"y : tf.random_uniform([2,3],minval=2, maxval=3)\")\n",
    "print_tensor(y)\n",
    "z = tf.Variable(y)\n",
    "print('tf.get_collection(\"variables\")[-1]')\n",
    "print(tf.get_collection('variables')[-1])\n",
    "sess.run(tf.variables_initializer([tf.get_collection('variables')[-1]]))\n",
    "print(\"z : tf.Variable(y)\")\n",
    "print_tensor(z)\n",
    "w = tf.Variable(tf.constant([0,1]))\n",
    "print(tf.get_collection('variables')[-1])\n",
    "sess.run(tf.variables_initializer([tf.get_collection('variables')[-1]]))\n",
    "print_tensor(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tf.constant([[-1,2],[3,-4]],dtype = tf.float32)\n",
      "[[-1.  2.]\n",
      " [ 3. -4.]]\n",
      "tf.sign(x)\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]]\n",
      "(tf.sign(x)+1)/2\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[-1,2],[3,-4]],dtype = tf.float32)\n",
    "print(\"x : tf.constant([[-1,2],[3,-4]],dtype = tf.float32)\")\n",
    "print_tensor(x)\n",
    "print(\"tf.sign(x)\")\n",
    "print_tensor(tf.sign(x))\n",
    "print(\"(tf.sign(x)+1)/2\")\n",
    "print_tensor((tf.sign(x)+1)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tf.floor([3.3])\n",
      "[ 3.]\n",
      "y = tf.floor([-3.4])\n",
      "[-4.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.floor([3.3])\n",
    "y = tf.floor([-3.4])\n",
    "print(\"x = tf.floor([3.3])\")\n",
    "print_tensor(x)\n",
    "print(\"y = tf.floor([-3.4])\")\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"hi/Squeeze:0\", shape=(3,), dtype=float32)\n",
      "Tensor(\"hi/Squeeze_1:0\", shape=(3,), dtype=float32)\n",
      "[ 2.   3.   4.5]\n",
      "[ 1.    1.    0.25]\n",
      "(array([ 4.        ,  2.33333325], dtype=float32), array([ 0.66666669,  1.5555557 ], dtype=float32))\n",
      "(3.1666667, 1.8055555)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[3,4,5],[1,2,4]],dtype = tf.float32)\n",
    "mean, var = tf.nn.moments(x,[0], name = 'hi')\n",
    "print(mean)\n",
    "print(var)\n",
    "print_tensor(mean)\n",
    "print_tensor(var)\n",
    "print_tensor(tf.nn.moments(x,[1],name = 'hi2'))\n",
    "print_tensor(tf.nn.moments(x,[0,1],name = 'hi2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  9  1 11]\n",
      " [ 2  5 12 10]\n",
      " [ 7  3  8  6]]\n",
      "[[ -4  -9  -1 -11]\n",
      " [ -2  -5 -12 -10]\n",
      " [ -7  -3  -8  -6]]\n",
      "[[-1 -4]\n",
      " [-2 -5]\n",
      " [-3 -6]]\n",
      "[[2 0]\n",
      " [0 1]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([4,9,1,11,2,5,12,10,7,3,8,6], shape=[3,4])\n",
    "a_v = tf.Variable(a)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(a)\n",
    "print_tensor(-a_v)\n",
    "values, indices = tf.nn.top_k(-a_v, k=2, sorted=True)\n",
    "print_tensor(values)\n",
    "print_tensor(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.size, tf.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tf.size(x)\n",
      "4\n",
      "tf.rank(x)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2],[3,4]])\n",
    "print_tensor(x)\n",
    "print(\"tf.size(x)\")\n",
    "print_tensor(tf.size(x))\n",
    "print(\"tf.rank(x)\")\n",
    "print_tensor(tf.rank(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.range, tf.size, tf.gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[3 4 5 6]\n",
      "tf.size(x)\n",
      "4\n",
      "tf.range(0, tf.size(x))\n",
      "[0 1 2 3]\n",
      "0.5+tf.range(6)/10\n",
      "[ 0.2         0.34285714  0.48571429  0.62857143  0.77142857  0.91428571]\n",
      "tf.gather(x, [1,2,2,1])\n",
      "[4 5 5 4]\n",
      "tf.gather(x, [1,3,0])\n",
      "[4 6 3]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([3,4,5,6])\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"tf.size(x)\")\n",
    "print_tensor(tf.size(x))\n",
    "print(\"tf.range(0, tf.size(x))\")\n",
    "print_tensor(tf.range(0, tf.size(x)))\n",
    "print(\"0.5+tf.range(6)/10\")\n",
    "print_tensor(0.2+tf.range(6)/7)\n",
    "print(\"tf.gather(x, [1,2,2,1])\")\n",
    "print_tensor(tf.gather(x,[1,2,2,1]))\n",
    "print(\"tf.gather(x, [1,3,0])\")\n",
    "print_tensor(tf.gather(x,[1,3,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.assign(ref, value, validate_shape, use_locking)\n",
    "    ref : a mutable tensor variable, may be unitialized\n",
    "    value : a Tensor, same time as ref the value assigned to variable\n",
    "    validate shape : default true, ture the shape of 'value' matches the shape of the tensor assigned \n",
    "                    otherwise shape of 'ref' = shape of 'value'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  3.  4.]\n",
      "[ 2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.], name = 'x')\n",
    "x_op = tf.assign(x, [2.,3.,4.], validate_shape=False,name= 'tempx')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print_tensor(x_op)\n",
    "print_tensor(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.get_default_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7faaf96de2e8>\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7faaf96de2e8>\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(4.0)\n",
    "print(c.graph)\n",
    "print(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.is_inf, tf.is_finite, tf.is_nan\n",
    "    Must be float in tf.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print_tensor(tf.is_inf(tf.log(0.0)))\n",
    "print_tensor(tf.is_inf(tf.log(0.5)))\n",
    "print_tensor(tf.is_finite(1.0))\n",
    "print_tensor(tf.is_nan(-tf.log(-1.0)))\n",
    "print_tensor(tf.is_nan(-tf.log(1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2.0)\n",
    "y = tf.identity(x)\n",
    "print_tensor(x)\n",
    "print_tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cond_2/Merge:0\", shape=(), dtype=int32)\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(2)\n",
    "y = tf.constant(5)\n",
    "def f1(): \n",
    "    return tf.multiply(x, 17)\n",
    "def f2(): \n",
    "    return tf.add(y, 23)\n",
    "r = tf.cond(tf.less(x, y), f1, f2)\n",
    "print(r)\n",
    "print_tensor(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.clip_by_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print_tensor(tf.clip_by_value(0, clip_value_max=5, clip_value_min=3))\n",
    "print_tensor(tf.clip_by_value(7, clip_value_max=5, clip_value_min=3))\n",
    "print_tensor(tf.clip_by_value(4, clip_value_max=5, clip_value_min=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.conv2d_transpose\n",
    "* **value** : \n",
    ">[batch, height, width, in_channels] for NHWC  \n",
    ">[batch, in_channels, height, width] for NCHW\n",
    "* **filter** : [height, width, output_channels, in_channels]\n",
    "* **output_shape** : output shape of the deconvolution op.\n",
    "* **strides** : the stride of the sliding window for each dimension of the input tensor.\n",
    "* **padding** : 'VALID' or 'SAME'\n",
    "* **data_format** : 'NHWC' or 'NCHW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : (1, 4, 4, 1)\n",
      "[[ 1.  2.  1.  2.]\n",
      " [ 2.  6.  2.  6.]\n",
      " [ 1.  2.  1.  2.]\n",
      " [ 2.  6.  2.  6.]]\n",
      "Filter : (2, 2, 1, 1)\n",
      "[[ 0.  1.]\n",
      " [-1.  0.]]\n",
      "Output : (1, 4, 4, 1)\n",
      "[[ 0.  1.  2.  1.]\n",
      " [-1.  0.  5.  0.]\n",
      " [-2. -5.  0. -5.]\n",
      " [-1.  0.  5.  0.]]\n",
      "Output : (1, 7, 7, 1)\n",
      "[[ 0.  1.  0.  2.  0.  1.  0.]\n",
      " [-1.  0. -2.  0. -1.  0. -2.]\n",
      " [ 0.  2.  0.  6.  0.  2.  0.]\n",
      " [-2.  0. -6.  0. -2.  0. -6.]\n",
      " [ 0.  1.  0.  2.  0.  1.  0.]\n",
      " [-1.  0. -2.  0. -1.  0. -2.]\n",
      " [ 0.  2.  0.  6.  0.  2.  0.]]\n",
      "Output : (1, 8, 8, 1)\n",
      "[[ 0.  1.  0.  2.  0.  1.  0.  2.]\n",
      " [-1.  0. -2.  0. -1.  0. -2.  0.]\n",
      " [ 0.  2.  0.  6.  0.  2.  0.  6.]\n",
      " [-2.  0. -6.  0. -2.  0. -6.  0.]\n",
      " [ 0.  1.  0.  2.  0.  1.  0.  2.]\n",
      " [-1.  0. -2.  0. -1.  0. -2.  0.]\n",
      " [ 0.  2.  0.  6.  0.  2.  0.  6.]\n",
      " [-2.  0. -6.  0. -2.  0. -6.  0.]]\n",
      "Output : (1, 10, 10, 1)\n",
      "[[ 0.  1.  0.  0.  2.  0.  0.  1.  0.  0.]\n",
      " [-1.  0.  0. -2.  0.  0. -1.  0.  0. -2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  0.  6.  0.  0.  2.  0.  0.]\n",
      " [-2.  0.  0. -6.  0.  0. -2.  0.  0. -6.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  2.  0.  0.  1.  0.  0.]\n",
      " [-1.  0.  0. -2.  0.  0. -1.  0.  0. -2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  2.  0.  0.  6.  0.  0.  2.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2],[2, 6]], dtype = tf.float32)\n",
    "x = tf.tile(x,[2,2])\n",
    "y = tf.constant([[0,1],[-1,0]], dtype = tf.float32)\n",
    "x_r = tf.reshape(x, [1,4,4,1])\n",
    "y_r = tf.reshape(y, [2,2,1,1])\n",
    "print(\"Input : {}\".format(x_r.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"Filter : {}\".format(y_r.get_shape()))\n",
    "print_tensor(y)\n",
    "conv = tf.nn.conv2d_transpose(x_r, y_r, strides = [1,1,1,1], output_shape= [1,4,4,1], padding='SAME')\n",
    "print(\"Output : {}\".format(conv.get_shape()))\n",
    "print_tensor(tf.reshape(conv, [4, 4]))\n",
    "conv = tf.nn.conv2d_transpose(x_r, y_r, strides = [1,2,2,1], output_shape= [1,7,7,1], padding='SAME')\n",
    "print(\"Output : {}\".format(conv.get_shape()))\n",
    "print_tensor(tf.reshape(conv, [7, 7]))\n",
    "conv = tf.nn.conv2d_transpose(x_r, y_r, strides = [1,2,2,1], output_shape= [1,8,8,1], padding='SAME')\n",
    "print(\"Output : {}\".format(conv.get_shape()))\n",
    "print_tensor(tf.reshape(conv, [8, 8]))\n",
    "conv = tf.nn.conv2d_transpose(x_r, y_r, strides = [1,3,3,1], output_shape= [1,10,10,1], padding='SAME')\n",
    "print(\"Output : {}\".format(conv.get_shape()))\n",
    "print_tensor(tf.reshape(conv, [10, 10]))\n",
    "\n",
    "#print_tensortf.nn.conv2d_transpose(x_r, y_r, strides = [1,2,2,1], output_shape= [1,7,7,1], padding='SAME')))\n",
    "#print_tensortf.nn.conv2d_transpose(x_r, y_r, strides = [1,2,2,1], output_shape= [1,8,8,1], padding='SAME')))\n",
    "#print_tensortf.nn.conv2d_transpose(x_r, y_r, strides = [1,3,3,1], output_shape= [1,10,10,1], padding='SAME')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.conv2d\n",
    "\n",
    "**Data format** Default to be 'NHWC'\n",
    ">* 'NHWC' None(batch) height width channel\n",
    ">* 'NCHW' None(batch) channel height width\n",
    "\n",
    "input :  [batch, height, width, inchannel]  \n",
    "filter : [filter-height, filter-width, inchannel, outchannel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : (1, 4, 4, 1)\n",
      "[[ 1.  2.  1.  2.]\n",
      " [ 2.  6.  2.  6.]\n",
      " [ 1.  2.  1.  2.]\n",
      " [ 2.  6.  2.  6.]]\n",
      "Filter : (2, 2, 1, 1)\n",
      "[[ 0.  1.]\n",
      " [-1.  0.]]\n",
      "[[ 0. -5.  0. -6.]\n",
      " [ 5.  0.  5. -2.]\n",
      " [ 0. -5.  0. -6.]\n",
      " [ 6.  2.  6.  0.]]\n",
      "[[ 0. -5.  0.]\n",
      " [ 5.  0.  5.]\n",
      " [ 0. -5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2],[2,6]], dtype = tf.float32)\n",
    "x = tf.tile(x,[2,2])\n",
    "y = tf.constant([[0,1],[-1,0]], dtype = tf.float32)\n",
    "x_r = tf.reshape(x, [1,4,4,1])\n",
    "y_r = tf.reshape(y, [2,2,1,1])\n",
    "print(\"Input : {}\".format(x_r.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"Filter : {}\".format(y_r.get_shape()))\n",
    "print_tensor(y)\n",
    "conv = tf.nn.conv2d(input= x_r, filter = y_r\n",
    "                    , strides=[1,1,1,1], padding = 'SAME')\n",
    "print_tensor(tf.reshape(conv, [4, 4]))\n",
    "conv2 = tf.nn.conv2d(input= x_r, filter = y_r\n",
    "                     , strides=[1,1,1,1], padding = 'VALID')\n",
    "print_tensor(tf.reshape(conv2, [3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 3)\n",
      "[[ 1.  3.  4.]\n",
      " [ 2.  5.  6.]]\n",
      "y : (2, 2)\n",
      "[[ 1.  2.]\n",
      " [ 3.  4.]]\n",
      "tf.concat([x,y],1) : (2, 5)\n",
      "[[ 1.  3.  4.  1.  2.]\n",
      " [ 2.  5.  6.  3.  4.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.,3.,4.],[2.,5.,6.]])\n",
    "print(\"x : {}\".format(x.get_shape()))\n",
    "print_tensor(x)\n",
    "y = tf.constant([[1.,2.],[3.,4.]])\n",
    "print(\"y : {}\".format(y.get_shape()))\n",
    "print_tensor(y)\n",
    "z = tf.concat([x,y], 1)\n",
    "print(\"tf.concat([x,y],1) : {}\".format(z.get_shape()))\n",
    "print_tensor(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[ 1.  3.  4.]\n",
      " [ 2.  5.  6.]]\n",
      "tf.nn.softmax(x, dim=-1)\n",
      "[[ 0.03511902  0.25949645  0.70538449]\n",
      " [ 0.01321289  0.26538792  0.72139919]]\n",
      "tf.nn.softmax(x, dim=0)\n",
      "[[ 0.26894143  0.11920291  0.11920291]\n",
      " [ 0.7310586   0.88079703  0.88079703]]\n",
      "tf.nn.softmax(x, dim=1) which makes error, last dim should be -1\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.,3.,4.],[2.,5.,6.]])\n",
    "print(\"x\")\n",
    "print_tensor(x)\n",
    "print(\"tf.nn.softmax(x, dim=-1)\")\n",
    "print_tensor(tf.nn.softmax(x,dim=-1))\n",
    "print(\"tf.nn.softmax(x, dim=0)\")\n",
    "print_tensor(tf.nn.softmax(x,dim=0))\n",
    "print(\"tf.nn.softmax(x, dim=1) which makes error, last dim should be -1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.softmax_cross_entropy_with_logits\n",
    " \n",
    "If using exclusive **labels** \n",
    "=> see `sparse_softmax_cross_entropy_with_logits`.  \n",
    "**WARNING:** \n",
    "1. op expects unscaled logits (Do not softmax before)  \n",
    "2. `logits` and `labels` must have the same shape `[batch_size, num_classes]`\n",
    "  and the same dtype (either `float16`, `float32`, or `float64`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[ 0.5         1.5         0.1       ]\n",
      " [ 2.20000005  1.29999995  1.70000005]]\n",
      "x_true\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "First method\n",
      "x_softmax\n",
      "[[ 0.22786303  0.61939591  0.15274116]\n",
      " [ 0.49674627  0.20196195  0.30129185]]\n",
      "[ 0.47901061  1.19967592]\n",
      "Second method\n",
      "[ 0.47901064  1.19967592]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]])\n",
    "print(\"x\")\n",
    "print(sess.run(x))\n",
    "x_true = tf.constant([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]])\n",
    "print(\"x_true\")\n",
    "print(sess.run(x_true))\n",
    "\n",
    "print(\"First method\")\n",
    "print(\"x_softmax\")\n",
    "x_softmax = tf.nn.softmax(x,dim = -1)\n",
    "print(sess.run(x_softmax))\n",
    "temp = tf.reduce_sum(x_true * tf.log(x_softmax),1)\n",
    "print(sess.run(-temp))\n",
    "\n",
    "print(\"Second method\")\n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels= x_true, logits = x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  tf.nn.sparse_softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[ 0.5         1.5         0.1       ]\n",
      " [ 2.20000005  1.29999995  1.70000005]]\n",
      "x_true\n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "tf.nn.softmax_cross_entropy_with_logits\n",
      "[ 0.47901064  1.19967592]\n",
      "tf.nn.sparse_softmax_cross_entropy_with_logits\n",
      "[ 0.47901064  1.19967592]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]])\n",
    "#batch_size = 2 num_classes = 3\n",
    "print(\"x\")\n",
    "print(sess.run(x))\n",
    "x_true = tf.constant([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]])\n",
    "print(\"x_true\")\n",
    "print(sess.run(x_true))\n",
    "print(\"tf.nn.softmax_cross_entropy_with_logits\")\n",
    "print(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels= x_true, logits = x)))\n",
    "print(\"tf.nn.sparse_softmax_cross_entropy_with_logits\")\n",
    "print(sess.run(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=[1,2], logits = x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.nn.sigmoid_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "[[1.0, 3.0, 4.0], [2.0, 5.0, 6.0]]\n",
      "x_true\n",
      "[[1.0, 1.0, 0.0], [0.0, 1.0, 0.0]]\n",
      "tf.sigmoid(x)\n",
      "[[ 0.7310586   0.95257413  0.98201376]\n",
      " [ 0.88079703  0.99330717  0.99752742]]\n",
      "First method\n",
      "[[ 0.31326166  0.04858734  4.01814842]\n",
      " [ 2.12692761  0.00671532  6.00249338]]\n",
      "Second method\n",
      "[[ 0.31326169  0.04858735  4.01814985]\n",
      " [ 2.12692809  0.00671535  6.00247574]]\n"
     ]
    }
   ],
   "source": [
    "x = [[1.,3.,4.],[2.,5.,6.]]\n",
    "print(\"x\")\n",
    "print(x)\n",
    "x_true = [[1.,1.,0.],[0.,1.,0.]]\n",
    "print(\"x_true\")\n",
    "print(x_true)\n",
    "x_sigmoid = tf.sigmoid(x)\n",
    "print(\"tf.sigmoid(x)\")\n",
    "print_tensor(x_sigmoid)\n",
    "print(\"First method\")\n",
    "ones = tf.ones_like(x_sigmoid)\n",
    "print(-sess.run(x_true*tf.log(x_sigmoid)+(ones-x_true)*tf.log(ones-x_sigmoid)))\n",
    "print(\"Second method\")\n",
    "print_tensor(tf.nn.sigmoid_cross_entropy_with_logits(labels = x_true, logits= x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalize with tf.reduce_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  0  1]\n",
      " [ 2  3  4]]\n",
      "[[2 3 4]\n",
      " [5 6 7]]\n",
      "[[ 3  5  7]\n",
      " [ 6  8 10]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,5,6]])\n",
    "y = tf.constant([2,2,2])\n",
    "print_tensor(x-y)\n",
    "print_tensor(x+[1])\n",
    "print_tensor(x+[2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Nornalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 3)\n",
      "mean = tf.reduce_mean(x,[0])\n",
      "[ 2.5  4.   6. ]\n",
      "x-mean\n",
      "[[-1.5 -2.  -3. ]\n",
      " [ 1.5  2.   3. ]]\n",
      "std =tf.reduce_mean(tf.square(x-mean),[0])\n",
      "[ 2.25  4.    9.  ]\n",
      "(x-mean)/std\n",
      "[[-0.66666669 -0.5        -0.33333334]\n",
      " [ 0.66666669  0.5         0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,6,9]], dtype = tf.float32)\n",
    "print(\"x : {}\".format(sess.run(x).shape))\n",
    "mean = tf.reduce_mean(x,[0])\n",
    "print(\"mean = tf.reduce_mean(x,[0])\")\n",
    "print_tensor(mean)\n",
    "print(\"x-mean\")\n",
    "print_tensor(x-mean)\n",
    "std =tf.reduce_mean(tf.square(x-mean),[0])\n",
    "print(\"std =tf.reduce_mean(tf.square(x-mean),[0])\")\n",
    "print_tensor(std)\n",
    "print(\"(x-mean)/std\")\n",
    "print_tensor((x-mean)/std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_shape(), get_shape().as_list(), get_shape().ndims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "x.get_shape().ndims\n",
      "2\n",
      "tf.expand_dims(x, dim=1).get_shape().ndims\n",
      "3\n",
      "Can get shape of variabless\n",
      "a = tf.Variable(x)\n",
      "a.get_shape()\n",
      "(2, 3)\n",
      "2\n",
      "[2, 3]\n",
      "<class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(\"x : {}\".format(x.get_shape()))\n",
    "print_tensor(x)\n",
    "print(\"x.get_shape().ndims\")\n",
    "print(x.get_shape().ndims)\n",
    "print(\"tf.expand_dims(x, dim=1).get_shape().ndims\")\n",
    "print(tf.expand_dims(x, dim=1).get_shape().ndims)\n",
    "print(\"Can get shape of variabless\")\n",
    "a= tf.Variable(x)\n",
    "print(\"a = tf.Variable(x)\")\n",
    "print(\"a.get_shape()\")\n",
    "print(a.get_shape())\n",
    "print(a.get_shape()[0])\n",
    "print(a.get_shape().as_list())\n",
    "print(type(a.get_shape()))\n",
    "print(type(a.get_shape().as_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.shape() v.s. get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2, 3])\n",
    "y = tf.reshape(x, [tf.shape(x)[0], -1])\n",
    "z = tf.reshape(x, [-1, get_shape(x)[1]*get_shape(x)[2]])\n",
    "#w = tf.reshape(x, [get_shape(x)[0], -1]) error\n",
    "print(sess.run(y, feed_dict={x : np.zeros([1,2,3])}).shape)\n",
    "print(sess.run(z, feed_dict={x : np.zeros([1,2,3])}).shape)\n",
    "#print(sess.run(w, feed_dict={x : np.zeros([1,2,3])}).shape) error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(uninitialized)\n",
      "<tf.Variable 'Variable_9:0' shape=(2, 2) dtype=int32_ref>\n",
      "constant\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "tf.shape(variable)\n",
      "Tensor(\"Shape_8:0\", shape=(2,), dtype=int32)\n",
      "[2 2]\n",
      "variable.get_shape()\n",
      "(2, 2)\n",
      "tf.shape(constant)\n",
      "Tensor(\"Shape_9:0\", shape=(2,), dtype=int32)\n",
      "[2 2]\n",
      "constant.get_shape()\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "variable = tf.Variable([[1,2],[3,4]])\n",
    "constant = tf.constant([[1,2],[3,4]])\n",
    "print(\"variable(uninitialized)\")\n",
    "print(variable)\n",
    "print(\"constant\")\n",
    "print_tensor(constant)\n",
    "print(\"tf.shape(variable)\")\n",
    "s_v = tf.shape(variable)\n",
    "print(s_v)\n",
    "print_tensor(s_v)\n",
    "print(\"variable.get_shape()\")\n",
    "g_v = variable.get_shape()\n",
    "print(g_v)\n",
    "print(\"tf.shape(constant)\")\n",
    "s_c = tf.shape(constant)\n",
    "print(s_c)\n",
    "print_tensor(s_c)\n",
    "print(\"constant.get_shape()\")\n",
    "g_c = constant.get_shape()\n",
    "print(g_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.tile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "tf.tile(x,[2,3]): (4, 9)\n",
      "[[1 2 3 1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6 4 5 6]\n",
      " [1 2 3 1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(\"x : {}\".format(sess.run(x).shape))\n",
    "print_tensor(x)\n",
    "print(\"tf.tile(x,[2,3]): {}\".format(sess.run(tf.tile(x,[2,3])).shape))\n",
    "print_tensor(tf.tile(x,[2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "tf.expand_dims(x, dim=1) : (2, 1, 3)\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[4 5 6]]]\n",
      "tf.expand_dims(x, dim=0) : (1, 2, 3)\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "tf.expand_dims(x, dim=2) : (2, 3, 1)\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]]\n",
      "tf.expand_dims(x, dim=-1) : (2, 3, 1)\n",
      "[[[1]\n",
      "  [2]\n",
      "  [3]]\n",
      "\n",
      " [[4]\n",
      "  [5]\n",
      "  [6]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"tf.expand_dims(x, dim=3) : {}\".format(sess.run(tf.expand_dims(x, dim=3)).shape))\\nprint_tensortf.expand_dims(x, dim=3)))\\nError occured\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(\"x : {}\".format(sess.run(x).shape))\n",
    "print_tensor(x)\n",
    "print(\"tf.expand_dims(x, dim=1) : {}\".format(sess.run(tf.expand_dims(x, dim=1)).shape))\n",
    "print_tensor(tf.expand_dims(x, dim=1))\n",
    "print(\"tf.expand_dims(x, dim=0) : {}\".format(sess.run(tf.expand_dims(x, dim=0)).shape))\n",
    "print_tensor(tf.expand_dims(x, dim=0))\n",
    "print(\"tf.expand_dims(x, dim=2) : {}\".format(sess.run(tf.expand_dims(x, dim=2)).shape))\n",
    "print_tensor(tf.expand_dims(x, dim=2))\n",
    "print(\"tf.expand_dims(x, dim=-1) : {}\".format(sess.run(tf.expand_dims(x, dim=-1)).shape))\n",
    "print_tensor(tf.expand_dims(x, dim=-1))\n",
    "'''\n",
    "print(\"tf.expand_dims(x, dim=3) : {}\".format(sess.run(tf.expand_dims(x, dim=3)).shape))\n",
    "print_tensortf.expand_dims(x, dim=3)))\n",
    "Error occured\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [2, 3]\n",
      "y = tf.expand_dims(x, dim=1)\n",
      "y : [1, 2, 3]\n",
      "z : tf.expand_dims(y, dim=-1)\n",
      "z : [1, 2, 3, 1]\n",
      "w = tf.squeeze(z, axis = -1)\n",
      "w : [1, 2, 3]\n",
      "w2 = tf.squeeze(z)\n",
      "w2 : [2, 3]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(\"x : {}\".format(get_shape(x)))\n",
    "y = tf.expand_dims(x, dim=0)\n",
    "print(\"y = tf.expand_dims(x, dim=1)\")\n",
    "print(\"y : {}\".format(get_shape(y)))\n",
    "z = tf.expand_dims(y, dim=-1)\n",
    "print(\"z : tf.expand_dims(y, dim=-1)\")\n",
    "print(\"z : {}\".format(get_shape(z)))\n",
    "w = tf.squeeze(z, axis= -1)\n",
    "print(\"w = tf.squeeze(z, axis = -1)\")\n",
    "print(\"w : {}\".format(get_shape(w)))\n",
    "w2 = tf.squeeze(z)\n",
    "print(\"w2 = tf.squeeze(z)\")\n",
    "print(\"w2 : {}\".format(get_shape(w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.stack, tf.unstack, tf.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[array([1, 2, 3], dtype=int32), array([4, 5, 6], dtype=int32)]\n",
      "[array([[1, 2, 3]], dtype=int32), array([[4, 5, 6]], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.constant([1,2,3])\n",
    "v2 = tf.constant([4,5,6])\n",
    "t = tf.stack([v1,v2])\n",
    "print_tensor(t)\n",
    "print_tensor(tf.unstack(t))\n",
    "print_tensor(tf.split(t, 2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 30]\n",
      "[5 4]\n",
      "[ 5 15]\n",
      "[ 5 11]\n",
      "[ 5 10]\n",
      "[ 3  5 10]\n",
      "[ 5  1 30]\n",
      "[5 4]\n",
      "[ 5 15]\n",
      "[ 5 11]\n"
     ]
    }
   ],
   "source": [
    "value = tf.random_normal([5,30],stddev=0.1)\n",
    "print_tensor(tf.shape(value))\n",
    "\n",
    "split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n",
    "print_tensor(tf.shape(split0))\n",
    "print_tensor(tf.shape(split1))\n",
    "print_tensor(tf.shape(split2))\n",
    "split0, split1, split2 = tf.split(value, 3, axis=1)\n",
    "print_tensor(tf.shape(split0))\n",
    "splits = tf.split(value, 3, axis=1)\n",
    "print_tensor(tf.shape(splits))\n",
    "splits = tf.split(value, 5, axis=0)\n",
    "print_tensor(tf.shape(splits))\n",
    "\n",
    "split = tf.split(value, [4, 15, 11], 1)\n",
    "print_tensor(tf.shape(split[0]))\n",
    "print_tensor(tf.shape(split[1]))\n",
    "print_tensor(tf.shape(split[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "[3, 2]\n",
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]]\n",
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "x, y = tf.meshgrid(tf.range(2), tf.range(3))\n",
    "print_tensor(x)\n",
    "print(get_shape(x))\n",
    "print_tensor(y)\n",
    "print(get_shape(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.2]",
   "language": "python",
   "name": "conda-env-tf1.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
